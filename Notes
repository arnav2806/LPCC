### **Concise Viva Notes for Compiler Design**

---

#### **1. Phases of a Compiler**
1. **Lexical Analysis (Scanner)**  
   - Converts source code into tokens (e.g., identifiers, keywords).  
   - Removes whitespace, comments.  
   - Example: `int a = b + 5;` ‚Üí Tokens: `int`, `a`, `=`, `b`, `+`, `5`, `;`.

2. **Syntax Analysis (Parser)**  
   - Checks grammar using CFG (Context-Free Grammar).  
   - Generates parse trees (e.g., for `S ‚Üí id = E`).  
   - Example: `a = b + c` ‚Üí Valid syntax tree.

3. **Semantic Analysis**  
   - Ensures type compatibility, scope rules.  
   - Example: `int a; float b; a = b;` ‚Üí Error (type mismatch).

4. **Intermediate Code Generation**  
   - Produces machine-independent code (e.g., 3-address code, quadruples).  
   - Example: `t1 = b + c; a = t1`.

5. **Code Optimization**  
   - Improves efficiency (dead code elimination, loop optimization).  
   - Example:  
     ```c
     int a = 10;
     if (a > 5) { ... } else { ... } ‚Üí Eliminate else (always true).
     ```

6. **Code Generation**  
   - Converts intermediate code to target machine code.  
   - Example: `MOV R1, b; ADD R1, c; MOV a, R1`.

---

#### **2. Key Data Structures**
- **Symbol Table**: Stores identifiers, types, scope.  
- **Literal Table**: Holds constants (e.g., `=‚Äô5‚Äô`).  
- **Quadruples**: `(op, arg1, arg2, result)` for 3-address code.  
- **Triples**: Compact form of quadruples (no temporary names).  

---

#### **3. Macro Processors**
- **Macro Definition**:  
  ```assembly
  MACRO ADD1 &X, &Y
    MOVER AREG, &X
    ADD AREG, &Y
  MEND
  ```
- **Expansion**: Replaces macro calls with definitions.  
- **Data Structures**:  
  - **MNT (Macro Name Table)**: Name, parameters, start index.  
  - **MDT (Macro Definition Table)**: Expanded instructions.  

---

#### **4. Assemblers**
- **Two-Pass Assembler**:  
  - **Pass 1**: Builds symbol table, assigns addresses.  
  - **Pass 2**: Generates machine code using symbol table.  
- **Directives**:  
  - `DC` (Define Constant), `DS` (Define Storage).  
  - `EQU` (Equate), `LTORG` (Literal pool).  

---

#### **5. Loaders and Linkers**
- **Loader**: Loads executable into memory.  
  - Types: Absolute, Relocating, Dynamic.  
- **Linker**: Combines object files, resolves symbols.  
  - Example: `printf()` in library linked to user code.  

---

#### **6. Syntax-Directed Translation (SDT)**
- **Attributes**:  
  - Synthesized (from children).  
  - Inherited (from parent/siblings).  
- **Example**:  
  ```plaintext
  E ‚Üí E1 + T { E.val = E1.val + T.val }
  ```

---

#### **7. Intermediate Code Forms**
1. **Postfix**: `a = b + c` ‚Üí `b c + a =`.  
2. **Syntax Tree**: Hierarchical representation.  
3. **3-Address Code**:  
   ```plaintext
   t1 = b + c
   a = t1
   ```
4. **Quadruples**:  
   | op  | arg1 | arg2 | result |
   |-----|------|------|--------|
   | +   | b    | c    | t1     |
   | =   | t1   | -    | a      |

---

#### **8. Code Optimization Techniques**
- **Local**: Peephole (redundant load elimination).  
- **Global**: Loop invariant removal, constant folding.  
- **Example**:  
  ```c
  x = 2 * 3; ‚Üí x = 6;  // Constant folding.
  ```

---

#### **9. Error Handling**
- **Lexical**: Illegal characters (`@` in C).  
- **Syntax**: Missing semicolon.  
- **Semantic**: Type mismatch (`int + string`).  

---

### **Sample Viva Questions**
1. **What is the role of the symbol table?**  
   - Stores identifiers, types, and scope for quick lookup.  

2. **How does a two-pass assembler work?**  
   - Pass 1: Processes symbols and literals. Pass 2: Generates machine code.  

3. **Differentiate between synthesized and inherited attributes.**  
   - Synthesized: Computed from child nodes. Inherited: From parent/siblings.  

4. **What is dead code elimination?**  
   - Removing unreachable code (e.g., `if (false) { ... }`).  

5. **Explain quadruples with an example.**  
   - Example: `t1 = b + c` ‚Üí `(+, b, c, t1)`.  

---

**Key Topics to Focus:**  
- Lexical/Syntax/Semantic analysis phases.  
- Macro expansion and assembler passes.  
- SDT attributes and intermediate code forms.  
- Optimization techniques.  

**Good Luck!** üöÄ
Great, thanks for the clarification!

Here's a set of concise, exam-ready notes for **Language Processor and Compiler Construction (LPCC)**. The content is structured **unit-wise**, with summaries, definitions, and key concepts commonly asked in exams.

---

## üìò LPCC Exam Notes

---

### üîπ **Unit 1: Introduction to Language Processors**

#### ‚úÖ Language Processing System:

* **Language processor**: Translates and processes programs written in high-level languages.
* **Phases of compiler**:

  1. **Lexical Analysis** ‚Äì Converts source code into tokens.
  2. **Syntax Analysis** ‚Äì Builds a parse tree using grammar rules.
  3. **Semantic Analysis** ‚Äì Ensures semantic correctness.
  4. **Intermediate Code Generation** ‚Äì Generates an intermediate representation (IR).
  5. **Code Optimization** ‚Äì Improves the IR for performance.
  6. **Code Generation** ‚Äì Translates IR into machine code.
  7. **Symbol Table Management** ‚Äì Stores information about identifiers.
  8. **Error Handling** ‚Äì Reports and recovers from errors.

#### ‚úÖ Language Translators:

* **Assembler** ‚Äì Converts assembly to machine code.
* **Interpreter** ‚Äì Executes code line-by-line.
* **Compiler** ‚Äì Translates whole code to machine language before execution.

---

### üîπ **Unit 2: Lexical Analysis**

#### ‚úÖ Lexical Analyzer:

* Recognizes tokens, removes whitespaces/comments, and communicates with the parser.
* **Token**: Pair of token name and attribute value.
* Implemented using **Finite Automata (FA)**.

#### ‚úÖ Regular Expressions:

* Used to define lexical patterns.
* Tools: **Lex** (automates lexical analyzer generation).

#### ‚úÖ Finite Automata:

* **NFA**: Multiple transitions possible.
* **DFA**: Single transition per input symbol.
* Conversion: NFA ‚ûù DFA ‚ûù Minimized DFA.

---

### üîπ **Unit 3: Syntax Analysis (Parsing)**

#### ‚úÖ Parser:

* Takes tokens and builds a **parse tree** based on grammar.
* Types of grammar: **Context-Free Grammar (CFG)** ‚Äì G = (V, T, P, S)

#### ‚úÖ Parsing Techniques:

* **Top-Down Parsing**:

  * **Recursive Descent** (manual implementation)
  * **LL(1) Parsing** (uses parsing table)
* **Bottom-Up Parsing**:

  * **Shift-Reduce Parsing**
  * **LR, SLR, LALR Parsers**

#### ‚úÖ FIRST and FOLLOW sets:

* Used for constructing parsing tables.

---

### üîπ **Unit 4: Semantic Analysis and Intermediate Code Generation**

#### ‚úÖ Semantic Analysis:

* Ensures logical correctness (e.g., type checking).
* Uses **syntax-directed definitions (SDD)**.

#### ‚úÖ Intermediate Code Generation:

* Translates high-level constructs to intermediate representation.
* Common forms:

  * **Three Address Code (TAC)** ‚Äì `x = y op z`
  * **Postfix Notation**
  * **Quadruples / Triples**

---

### üîπ **Unit 5: Code Optimization and Code Generation**

#### ‚úÖ Code Optimization:

* Improves intermediate code without changing output.
* **Types**:

  * **Peephole Optimization**
  * **Loop Optimization**
  * **Constant Folding**
  * **Dead Code Elimination**

#### ‚úÖ Code Generation:

* Converts IR to machine code.
* Considerations: CPU architecture, instruction selection, register allocation.

---

### üîπ **Unit 6: Symbol Tables and Error Handling**

#### ‚úÖ Symbol Table:

* Maintains variable/function info (name, type, scope).
* Implemented using:

  * **Hash Tables**
  * **Linked Lists**
  * **Binary Search Trees**

#### ‚úÖ Error Handling:

* **Lexical errors**: Illegal characters.
* **Syntax errors**: Invalid grammar structure.
* **Semantic errors**: Undeclared variables, type mismatch.
* **Runtime errors**: Division by zero, etc.

---

## üìå Tips for the Exam:

* Practice **FIRST/FOLLOW** sets and **parsing table** construction.
* Be thorough with **regular expressions and finite automata**.
* Revise **intermediate code generation examples (TAC)**.
* Solve sample questions on **LL(1), SLR parsing**.

---

Would you like this as a **PDF**, or want **sample questions and answers** added too?


UNIT I: Introduction to Systems Programming and Assemblers

‚úÖ Need of System Software

Provides the interface between hardware and user applications.

Helps manage hardware resources.

Examples: Operating systems, loaders, compilers, assemblers.

‚úÖ Components of System Software

Language Processors: Assemblers, Compilers, Interpreters.

Loaders and Linkers.

Macro Processors.

Debuggers, Text Editors.

‚úÖ Language Processing Activities

Program generation (Compilation, Assembly)

Program execution (Loading, Linking, Running)

‚úÖ Fundamentals of Language Processing

Lexical, Syntax, and Semantic analysis.

Intermediate code generation.

Code optimization and code generation.

‚úÖ Assemblers

Elements: Labels, Opcodes, Operands, Comments.

Assembly Scheme: Translating mnemonics into machine code.

Pass Structure:

Pass I: Build symbol table, handle labels.

Pass II: Generate machine code using symbol table.

Two-Pass Assembler: Efficiently separates symbol definition and usage.

UNIT II: Macroprocessors, Loaders, and Linkers

‚úÖ Macro Processor

Macro Definition and Call: Macros are code templates reused with parameters.

Macro Expansion: Replacing macro call with actual code.

Nested Macros: Macros calling other macros.

Advanced Facilities: Conditional macros, loops, parameters.

Two-Pass Macro Processor:

Pass I: Stores macro definitions.

Pass II: Expands macro calls.

‚úÖ Loaders

Schemes:

Compile and Go

Absolute Loader

General Loader

Subroutine Linkages: Handling function calls.

Relocation and Linking:

Relocation: Adjusting code based on load address.

Linking: Connecting modules.

Relocating and Direct Linking Loaders: Advanced loader types.

Overlay Structure: Load program in parts to save memory.

‚úÖ Linkers

Resolve external references.

Combine object modules.

UNIT III: Introduction to Compilers

‚úÖ Phase Structure of Compiler

Lexical Analysis

Syntax Analysis

Semantic Analysis

Intermediate Code Generation

Code Optimization

Code Generation

Error Handling and Symbol Table Management

‚úÖ Lexical Analyzer

Role: Converts character stream into tokens.

Input Buffering: Efficient reading of input.

Token Specification: Using regular expressions.

Recognition: DFA/Regex-based identification.

Uniform Symbol Table: Tracks identifiers and literals.

Errors: Invalid tokens.

‚úÖ LEX Tool

Used to generate lexical analyzers.

Contains rules in regex for token recognition.

UNIT IV: Parsers

‚úÖ Role of Parsers

Converts token stream to parse tree using grammar rules.

‚úÖ Top Down Parsers

Recursive Descent: Uses recursive functions for each grammar rule.

Predictive Parser (LL): Uses parsing table and FIRST/FOLLOW sets.

‚úÖ Bottom Up Parsers

Shift-Reduce Parser: Stack-based parser.

LR Parsers: Powerful bottom-up parser (LR(0), SLR, LALR).

‚úÖ YACC Tool

YACC Specification: Grammar + actions.

Automatic Parser Construction: Generates parser in C.

UNIT V: Semantic Analysis

‚úÖ Need

Ensure semantic correctness, e.g., type checking.

‚úÖ Syntax Directed Translation (SDT)

Associates semantic rules with grammar productions.

‚úÖ Syntax Directed Definitions (SDD)

Annotated parse trees with attributes (synthesized/inherited).

‚úÖ Translation Examples

Assignment, loops, conditionals, boolean expressions.

‚úÖ Type Checking and Conversion

Enforce type rules, perform implicit conversions.

‚úÖ Intermediate Code Formats

Postfix Notation

Parse Trees/Syntax Trees

Three Address Code (TAC): x = y op z

Quadruples and Triples: Data structures for TAC.

UNIT VI: Code Generation and Optimization

‚úÖ Code Generation

Issues: Instruction selection, register allocation, memory management.

Basic Blocks: Straight-line code sequence with no branches.

Flow Graphs: Graphs showing flow between blocks.

Simple Code Generator: Converts IR to machine code.

‚úÖ Code Optimization

Machine-Independent:

Peephole Optimization.

Common Subexpression Elimination.

Loop Invariant Code Motion.

Strength Reduction.

Induction Variables.

Machine Idioms.

Machine-Dependent:

Register assignment.

Instruction scheduling.

Use of specific hardware features.

Dynamic Programming: Optimize across basic blocks.
